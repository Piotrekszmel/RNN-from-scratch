# RNN-from-scratch
 Implementation of Recurrent Neural Network  from scratch

<br>
 <b> data </b>
 
 Twitter comments from 2015.08 as csv

 <b> prepocessing.py </b>
 
 Loads data. Based on provided data and  created vocabulary creates X_train, y_train

<b> layer.py </b>
 
 Forward and backpropagation of RNN layer

<b> gate.py </b>

 MultiplyGate:
  - forward and backpropagation of MultiplyGate used in RNN 
 MultiplyGate:
  - forward and backpropagation of AddGate used in RNN 
 
<b> activation.py </b>
 
 Sigmoid:
  - forward and backpropagation of sigmoid activation function
 
 Tanh:
  - forward and backpropagation of tanh activation function
 
<b> output.py </b>
 
 Softmax:
  - forward and backpropagation of softmax activation function
 
 <b> main.py </b>
 
  Example use of RNN



