# RNN-from-scratch
 Implementation of Recurrent Neural Network  from scratch


 1.<b> data </b>
 
 Twitter comments from 2015.08 as csv
 <br>
 2.<b> prepocessing.py </b>
 
 Loads data. Based on provided data and  created vocabulary creates X_train, y_train
 <br>
 3.<b> layer.py </b>
 
 Forward and backpropagation of RNN layer
 <br>
 4.<b> gate.py </b>

 MultiplyGate:
  - forward and backpropagation of MultiplyGate used in RNN 
 MultiplyGate:
  - forward and backpropagation of AddGate used in RNN 
 <br>
 5.<b> activation.py </b>
 
 Sigmoid:
  - forward and backpropagation of sigmoid activation function
 
 Tanh:
  - forward and backpropagation of tanh activation function
 <br>
 6.<b> output.py </b>
 
 Softmax:
  - forward and backpropagation of softmax activation function
 <br>
 7.<b> main.py </b>
 
  Example use of RNN



